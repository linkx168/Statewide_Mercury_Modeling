---
title: "metro_mercury"
output: html_document
date: "2024-05-09"
editor_options: 
  chunk_output_type: console
---

#Library
```{r}
library(tidyverse)
library(arrow)
library(LAGOSNE)
library(mwlaxeref)
library(mnsentinellakes)
library(corrplot)
library(performance)
library(brms)
library(lme4)
library(Matrix)
library(car)
library(tidybayes)
library(rstanarm)
library(bayesplot)
library(loo)
```

#Data
```{r}
#mercury data
hg <- read_csv(file.path("D:", "Shared drives", "Hansen Lab", "RESEARCH PROJECTS", "Statewide mercury modeling", "Data", "Mercury Data", "allfish_data_04042024_JLO.csv")) %>% 
  filter(!(is.na(LGTHIN) | is.na(HGPPM) | is.na(DOWID))) %>%   #removes samples with no hg, length, or dow data
  filter(TYPE %in% c("Lake", "LAKE")) %>% 
  mutate(DOWID = fixlakeid(DOWID)) %>% 
  filter(DOWID != "16000100") %>% 
  local_to_nhdhr(from_colname = "DOWID", states = "mn") %>% 
  mutate(nhdhr.id = str_remove(nhdhr.id, "nhdhr_")) %>% 
  select(SAMPLENO,
         WATERWAY,
         TYPE,
         LOCATION,
         DOWID,
         nhdhr.id,
         DATECOL2,
         YEARCOLL,
         SPEC,
         ANATHG,
         NOFISH,
         LGTHIN,
         WTLB,
         AGE,
         SEX,
         HGPPM,
         HGCODE,
         HGLAB,
         HGCMMT) %>% 
  rename(DOW = DOWID,
         nhdid = nhdhr.id) %>% 
  group_by(SPEC) %>% 
  mutate(scaled_length = scale(LGTHIN)) %>% 
  ungroup()

#connection to covariates
dnr_covary <- read_csv(file.path("D:", "Shared drives", "Hansen Lab", "RESEARCH PROJECTS", "Statewide mercury modeling", "Data", "Covariate Data", "MN_lakes_watershed_lulc_fromDNR.csv")) %>% 
  mutate(logit_wetlands = car::logit(Percent_Wetland),
         log_WS_Lake_Ratio = log(WS_Lake_Ratio))

dnr_covary %>% 
  ggplot() +
  geom_histogram(aes(logit_wetlands))

dnr_covary %>% 
  ggplot() +
  geom_histogram(aes(log_WS_Lake_Ratio))

scaled_dnr <- dnr_covary %>%
  mutate_at(vars(Total_Pasture_Hay_Hectares:log_WS_Lake_Ratio), scale) %>% 
  rename_with(~ paste0("scaled_", .), Total_Pasture_Hay_Hectares:log_WS_Lake_Ratio) 

dnr_covary <- dnr_covary %>% 
  left_join(scaled_dnr)
glimpse(dnr_covary)

#adding dnr covariates into the data
hg <- hg %>% 
  left_join(dnr_covary)
rm(dnr_covary, scaled_dnr)

#glm - for clarity and area values
glm <- read_csv(file.path("D:", "Shared drives", "Hansen Lab", "RESEARCH PROJECTS", "Statewide mercury modeling", "Data", "Covariate Data", "glm_lake_metadata.csv")) %>%
  filter(state == "MN") %>% 
  rename(nhdid = site_id) %>% 
  mutate(nhdid = gsub("^nhdhr_", "", nhdid)) %>% 
  mutate(clarity = case_when(is.infinite(clarity) ~ NA,
                             TRUE ~ clarity)) %>% 
  mutate(scaled_clarity = case_when(!is.na(clarity) ~ scale(clarity),
                                    TRUE ~ clarity),
         log_area = log(area),
         scaled_log_area = c(scale(log_area)))

glm %>% 
  ggplot() +
  geom_histogram(aes(log_area))

glm %>% 
  ggplot() +
  geom_histogram(aes(clarity))

hg <- hg %>% 
  left_join(glm) %>% 
  mutate(across(starts_with("scaled_"), as.vector))
rm(glm)
glimpse(hg)

#data for modeling - select for columns of use 
hg.model <- hg %>%
  select(WATERWAY,
         TYPE,
         DOW,
         nhdid,
         DATECOL2,
         YEARCOLL,
         SPEC,
         ANATHG,
         NOFISH,
         LGTHIN,
         scaled_length,
         HGPPM,
         Total_Wetland_Hectares,
         scaled_Total_Wetland_Hectares,
         Percent_Wetland,
         scaled_Percent_Wetland,
         logit_wetlands,
         scaled_logit_wetlands,
         WS_Lake_Ratio,
         log_WS_Lake_Ratio,
         scaled_log_WS_Lake_Ratio,
         scaled_WS_Lake_Ratio,
         centroid_lat,
         centroid_lon,
         max_depth,
         area,
         log_area,
         scaled_log_area,
         elevation,
         clarity,
         scaled_clarity)

#metro hg
metro.analysis <- hg.model %>% 
  #filtering for metro area lakes (11 county metro area)
  #hennepin, ramsey, washington, dakota, anoka, chisago, isanti, scott, carver, wright, sherburne
  filter(substr(DOW, 1, 2) %in% c("27", "62", "82", "19", "02", "13", "30", "70", "10", "86", "71")) %>% 
  #transforming hg 
  mutate(log_hg = log(HGPPM)) %>% 
  #scaling length by species 
  group_by(SPEC) %>% 
  mutate(scaled_length = c(scale(LGTHIN))) %>% 
  ungroup() %>% 
  #only looking at pike and walleye
  filter(SPEC %in% c("WAE", "NOP")) %>% 
  filter(YEARCOLL > 1996)
#only 471 samples prior to 1997

#statewide hg
statewide.analysis <- hg.model %>% 
  #transforming hg 
  mutate(log_hg = log(HGPPM)) %>% 
  #scaling length by species 
  group_by(SPEC) %>% 
  mutate(scaled_length = c(scale(LGTHIN))) %>% 
  ungroup() %>% 
  #only looking at pike and walleye
  filter(SPEC %in% c("WAE", "NOP")) %>% 
  filter(YEARCOLL > 1996)

rm(hg)
```

#Analysis 
```{r}
glimpse(metro.analysis)
write_csv(metro.analysis, "metro_analysis_raw_data.csv")

#some basic EDA
metro.analysis %>% 
  mutate(county_num = substr(DOW, 1,2)) %>% 
  group_by(county_num) %>% 
  summarise(n = n_distinct(DOW))
#reports the county number for the dow and how many lakes are within each one

#how many unique lakes within each year and how many total samples? How many samples of each species?
metro.analysis %>% 
  group_by(YEARCOLL) %>% 
  summarise(unqiue_lakes = n_distinct(DOW),
            n = n(),
            wae_samples = sum(SPEC == "WAE"),
            nop_samples = sum(SPEC == "NOP")) %>% 
  arrange(YEARCOLL) %>% 
  print(n = nrow(.))

#how many samples per year and lake?
metro.analysis %>% 
  group_by(DOW, YEARCOLL) %>% 
  summarise(wae = sum(SPEC == "WAE"),
            nop = sum(SPEC == "NOP")) %>% 
  mutate(wae = case_when(wae == "0" ~ NA,
                         TRUE ~ wae),
         nop = case_when(nop == "0" ~ NA,
                         TRUE ~ nop)) %>% 
  group_by(YEARCOLL) %>% 
  summarise(average.wae = mean(wae, na.rm =T),
            average.nop = mean(nop, na.rm = T)) %>% 
  print(n = nrow(.))
#This first calculates how many wae/nop per lake in a year then founds the average number of samples per lake in a year
#IF a lake was sample, this is how many samples were taken on average 

#average fish lengths 
metro.analysis %>% 
  group_by(SPEC) %>% 
  summarise(average_length = mean(LGTHIN), 
            n = n())

fit.metro <- brm(log_hg ~ scaled_length + SPEC + (1|DOW) + (1|YEARCOLL),
                 data = metro.analysis,
                 family = gaussian(),
                 iter = 10000,
                 warmup = 2000)
saveRDS(fit.metro, "metro_lake_fit.rds")
fit.metro <- readRDS("metro_lake_fit.rds")

plot(fit.metro)
summary(fit.metro)
plot(conditional_effects(fit.metro))

#random effects for DOW
lake_link <- read_csv("Data/lake_link.csv") %>% 
  distinct(lake_nhdid, .keep_all = T) %>% 
  rename(nhdid = lake_nhdid) %>% 
  right_join(metro.analysis) %>% 
  distinct(DOW, 
           nhdid, 
           lake_lat_decdeg, 
           lake_lon_decdeg)

dow_effect <- fit.metro %>% 
  spread_draws(r_DOW[DOW,])  %>% 
  mutate(DOW = as.factor(DOW),
         DOW = str_pad(DOW, width = 8, pad = "0")) %>% 
  left_join(lake_link) 

dow_effect %>% 
  filter(is.na(lake_lat_decdeg)) %>% 
  summarise(n = n_distinct(DOW))
#the 3 lakes without nhdids are very small lakes - can manually add in later

dow_effect %>% 
  median_qi(condition_mean = r_DOW, .width = c(.95, .66)) %>%
  ggplot(aes(y = DOW, x = condition_mean,  xmin = .lower, xmax = .upper)) +
  geom_pointinterval()


#map 
counties <- map_data("county") %>% 
  filter(region == "minnesota") %>% 
  filter(subregion %in% c("anoka", 
                          "chisago",
                          "scott",
                          "wright",
                          "carver",
                          "dakota",
                          "isanti",
                          "ramsey",
                          "sherburne",
                          "washington",
                          "hennepin"))


median_dow <- dow_effect %>% 
  group_by(DOW, lake_lat_decdeg, lake_lon_decdeg) %>% 
  summarise(conditional_median = median(r_DOW)) 

ggplot() +
  geom_polygon(data = counties, aes(x = long, y = lat, group = group), fill = NA, color = "black") +
  geom_point(data = median_dow, aes(lake_lon_decdeg, lake_lat_decdeg, color = conditional_median), size = 3) +
  scale_color_gradient(low = "blue", high = "orange") +
  theme(panel.background = element_rect(fill = "white"))
ggsave("metro_dow_random.png", width = 11, height = 7, dpi = 600)
  

#separate random draws for wae and nop
get_variables(fit.metro)

spec_dow_effect <- fit.metro %>% 
  spread_draws(b_Intercept, b_SPECWAE, r_DOW[DOW,])  %>% 
  mutate(DOW = as.factor(DOW),
         DOW = str_pad(DOW, width = 8, pad = "0")) %>% 
  mutate(nop.median = b_Intercept + r_DOW,
         wae.median = b_Intercept + b_SPECWAE + r_DOW,
         nop.hg = exp(nop.median),
         wae.hg = exp(wae.median)) %>% 
  group_by(DOW) %>% 
  median_qi(nop.hg, wae.hg, .width = c(.9, .66)) %>% 
  left_join(lake_link) %>% 
  mutate(state_threshold.nop = case_when(nop.hg >= 0.2 ~ "y", 
                                         nop.hg < 0.2 ~ "n"),
         state_threshold.wae = case_when(wae.hg >= 0.2 ~ "y",
                                         wae.hg < 0.2 ~ "n"))

#data provided to Finlay lab
data_finaly <- spec_dow_effect %>% 
  filter(.width == "0.9") %>% 
  rename(nop.hg.median = nop.hg,
         wae.hg.median = wae.hg) %>% 
  select(DOW,
         nhdid,
         lake_lat_decdeg,
         lake_lon_decdeg,
         nop.hg.median,
         nop.hg.lower,
         nop.hg.upper,
         wae.hg.median,
         wae.hg.lower,
         wae.hg.upper)
write_csv(data_finaly, "spec_dow_estimates.csv")

nop.lake.effect <- ggplot() +
  geom_polygon(data = counties, aes(x = long, y = lat, group = group), fill = NA, color = "black") +
  geom_point(data = spec_dow_effect, aes(lake_lon_decdeg, lake_lat_decdeg, color = nop.hg, shape = state_threshold.nop), size = 3) +
  scale_color_gradient(low = "blue", high = "orange") +
  theme(panel.background = element_rect(fill = "white"))
nop.lake.effect
ggsave("metro_nop_dow_effect.png", height = 7, width = 11, dpi = 600)

wae.lake.effect <- ggplot() +
  geom_polygon(data = counties, aes(x = long, y = lat, group = group), fill = NA, color = "black") +
  geom_point(data = spec_dow_effect, aes(lake_lon_decdeg, lake_lat_decdeg, color = wae.hg, shape = state_threshold.wae), size = 3) +
  scale_color_gradient(low = "blue", high = "orange") +
  theme(panel.background = element_rect(fill = "white"))
wae.lake.effect
ggsave("metro_wae_dow_effect.png", height = 7, width = 11, dpi = 600)

#year effect 
year_effect <- fit.metro %>% 
  spread_draws(r_YEARCOLL[YEARCOLL,]) 

year_effect %>% 
  median_qi(year_median = r_YEARCOLL, .width = c(.95, .66)) %>% 
  ggplot(aes(x = YEARCOLL, y = year_median, ymin = .lower, ymax = .upper)) +
  geom_pointinterval()
#shows mercury concentrations relative lows and highs over time
```

#statewide analysis 
```{r}
fit.statewide <- brm(log_hg ~ scaled_length + SPEC + (1|DOW) + (1|YEARCOLL),
                 data = statewide.analysis,
                 family = gaussian(),
                 iter = 10000,
                 warmup = 2000,
                 cores = 8)
saveRDS(fit.statewide, "statewide_lake_fit.rds")
fit.statewide <- readRDS("statewide_lake_fit.rds")

#random effects for DOW
lake_link <- read_csv("Data/lake_link.csv") %>% 
  distinct(lake_nhdid, .keep_all = T) %>% 
  rename(nhdid = lake_nhdid) %>% 
  right_join(statewide.analysis) %>% 
  distinct(DOW, 
           nhdid, 
           lake_lat_decdeg, 
           lake_lon_decdeg)

dow_effect <- fit.statewide %>% 
  spread_draws(r_DOW[DOW,])  %>% 
  mutate(DOW = as.factor(DOW),
         DOW = str_pad(DOW, width = 8, pad = "0")) %>% 
  left_join(lake_link) 

dow_effect %>% 
  filter(is.na(lake_lat_decdeg)) %>% 
  summarise(n = n_distinct(DOW))
#81 lakes where DOWs did not get an NHDID - will have to do some more exploration into that

#map 
mn <- map_data("state") %>% 
  filter(region == "minnesota")

median_dow <- dow_effect %>% 
  group_by(DOW, lake_lat_decdeg, lake_lon_decdeg) %>% 
  summarise(lake_medians = median(r_DOW)) 

ggplot() +
  geom_polygon(data = mn, aes(x = long, y = lat, group = group), fill = NA, color = "black") +
  geom_point(data = median_dow, aes(lake_lon_decdeg, lake_lat_decdeg, color = lake_medians), size = 3) +
  scale_color_gradient(low = "blue", high = "orange") +
  theme(panel.background = element_rect(fill = "white"),
        legend.position = "bottom")
ggsave("statewide_dow_random.png", width = 7, height = 11, dpi = 600)

spec_dow_effect <- fit.statewide %>% 
  spread_draws(b_Intercept, b_SPECWAE, r_DOW[DOW,])  %>% 
  mutate(DOW = as.factor(DOW),
         DOW = str_pad(DOW, width = 8, pad = "0")) %>% 
  mutate(nop.median = b_Intercept + r_DOW,
         wae.median = b_Intercept + b_SPECWAE + r_DOW,
         nop.hg = exp(nop.median),
         wae.hg = exp(wae.median)) %>% 
  group_by(DOW) %>% 
  median_qi(nop.hg, wae.hg, .width = c(.9, .66)) %>% 
  left_join(lake_link) %>% 
  mutate(state_threshold.nop = case_when(nop.hg >= 0.2 ~ "y", 
                                         nop.hg < 0.2 ~ "n"),
         state_threshold.wae = case_when(wae.hg >= 0.2 ~ "y",
                                         wae.hg < 0.2 ~ "n"))

nop.lake.effect <- ggplot() +
  geom_polygon(data = mn, aes(x = long, y = lat, group = group), fill = NA, color = "black") +
  geom_point(data = spec_dow_effect, aes(lake_lon_decdeg, lake_lat_decdeg, color = nop.hg, shape = state_threshold.nop), size = 3) +
  scale_color_gradient(low = "blue", high = "orange") +
  theme(panel.background = element_rect(fill = "white"))
nop.lake.effect
ggsave("statewide_nop_dow_effect.png", height = 7, width = 11, dpi = 600)

wae.lake.effect <- ggplot() +
  geom_polygon(data = mn, aes(x = long, y = lat, group = group), fill = NA, color = "black") +
  geom_point(data = spec_dow_effect, aes(lake_lon_decdeg, lake_lat_decdeg, color = wae.hg, shape = state_threshold.wae), size = 3) +
  scale_color_gradient(low = "blue", high = "orange") +
  theme(panel.background = element_rect(fill = "white"))
wae.lake.effect
ggsave("statewide_wae_dow_effect.png", height = 7, width = 11, dpi = 600)
```

# whitefish chain of lakes 
```{r}
library(tidyverse)

all_data <- read_csv(file.path("D:", "Shared drives", "Hansen Lab", "RESEARCH PROJECTS", "Statewide mercury modeling", "Zebra Mussel Baci Analysis", "Data", "baci_data_29april2025.csv")) %>% 
  #create lengths in mm from inches
  mutate(lgthmm = lgthin/0.0393701) %>% 
  #group by species and lag analysis to scale length for modeling
  group_by(species, lag) %>% 
  mutate(scaled_length = c(scale(lgthmm))) %>% 
  ungroup() %>% 
  filter(lag == 2)

all_data %>% 
  filter(lake_id %in% c("18031200", "18031500", "18037800")) %>% 
  group_by(lake_name, species, zm_sample) %>% 
  count() %>% 
  print(n = nrow(.))

all_data %>% 
  filter(species %in% c("LMB", "NOP", "WAE")) %>% 
  filter(lake_id %in% c("18031200", "18031500", "18037800")) %>% 
  mutate(species = as.factor(case_when(species == "LMB" ~ "Largemouth Bass",
                             species == "NOP" ~ "Northern Pike",
                             species == "WAE" ~ "Walleye")),
         species = factor(species, levels = c("Walleye", "Northern Pike", "Largemouth Bass"))) %>% 
  ggplot() +
  geom_point(aes(lgthin, hgppm, color = zm_sample)) +
  geom_smooth(aes(lgthin, hgppm, color = zm_sample),
               method = "gam", formula = y ~ s(x, k = 4),
              se = F) +
  scale_color_manual("", values = c("lightblue", "salmon"), labels = c("Pre", "Post")) +
  facet_grid(lake_name ~ species, scales = "free") +
  labs(x = "Length (Inches)",
       y = "Fish Tissue Mercury Concentratino (ppm)") +
  theme_minimal()
ggsave("Whitefish_area_lakes.jpg", height = 5, width = 7, dpi = 600)
```

