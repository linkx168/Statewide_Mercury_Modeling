---
title: "Hg_Prediction_Modeling"
author: "Denver Link"
date: "2024-02-27"
output: html_document
editor_options: 
  chunk_output_type: console
---

#To do:

#Library
```{r}
library(tidyverse)
library(arrow)
library(LAGOSNE)
library(mwlaxeref)
library(mnsentinellakes)
library(corrplot)
library(performance)
library(brms)
library(lme4)
library(Matrix)
library(car)
library(tidybayes)
library(rstanarm)
library(bayesplot)
library(loo)
```

#Data
```{r}
#mercury data
hg <- read_csv(file.path("D:", "Shared drives", "Hansen Lab", "RESEARCH PROJECTS", "Statewide mercury modeling", "Data", "Mercury Data", "allfish_data_20231102_IT.csv")) %>% 
  filter(!(is.na(LGTHIN) | is.na(HGPPM) | is.na(DOWID))) %>% #removes samples with no hg, length, or dow data
  mutate(DOWID = fixlakeid(DOWID)) %>% 
  filter(DOWID != "16000100") %>% 
  local_to_nhdhr(from_colname = "DOWID", states = "mn") %>% 
  mutate(nhdhr.id = str_remove(nhdhr.id, "nhdhr_")) %>% 
  select(SAMPLENO,
         WATERWAY,
         TYPE,
         LOCATION,
         DOWID,
         nhdhr.id,
         DATECOL2,
         YEARCOLL,
         SPEC,
         ANATHG,
         NOFISH,
         LGTHIN,
         WTLB,
         AGE,
         SEX,
         HGPPM,
         HGCODE,
         HGLAB,
         HGCMMT) %>% 
  rename(DOW = DOWID,
         nhdid = nhdhr.id) %>% 
  group_by(SPEC) %>% 
  mutate(scaled_length = scale(LGTHIN)) %>% 
  ungroup()

#connection to covariates
dnr_covary <- read_csv(file.path("D:", "Shared drives", "Hansen Lab", "RESEARCH PROJECTS", "Statewide mercury modeling", "Data", "Covariate Data", "MN_lakes_watershed_lulc_fromDNR.csv")) %>% 
  mutate(logit_wetlands = car::logit(Percent_Wetland),
         log_WS_Lake_Ratio = log(WS_Lake_Ratio)) 

dnr_covary %>% 
  ggplot() +
  geom_histogram(aes(logit_wetlands))

dnr_covary %>% 
  ggplot() +
  geom_histogram(aes(log_WS_Lake_Ratio))

scaled_dnr <- dnr_covary %>%
  mutate_at(vars(Total_Pasture_Hay_Hectares:logit_wetlands), scale) %>% 
  rename_with(~ paste0("scaled_", .), Total_Pasture_Hay_Hectares:logit_wetlands) 

dnr_covary <- dnr_covary %>% 
  left_join(scaled_dnr)
glimpse(dnr_covary)

#adding dnr covariates into the data
hg <- hg %>% 
  left_join(dnr_covary)
rm(dnr_covary, scaled_dnr)

#glm - for clarity and area values
glm <- read_csv(file.path("D:", "Shared drives", "Hansen Lab", "RESEARCH PROJECTS", "Statewide mercury modeling", "Data", "Covariate Data", "glm_lake_metadata.csv")) %>%
  filter(state == "MN") %>% 
  rename(nhdid = site_id) %>% 
  mutate(nhdid = gsub("^nhdhr_", "", nhdid)) %>% 
  mutate(clarity = case_when(is.infinite(clarity) ~ NA,
                             TRUE ~ clarity)) %>% 
  mutate(scaled_clarity = case_when(!is.na(clarity) ~ scale(clarity),
                                    TRUE ~ clarity),
         log_area = log(area))

glm %>% 
  ggplot() +
  geom_histogram(aes(log_area))

glm %>% 
  ggplot() +
  geom_histogram(aes(clarity))

hg <- hg %>% 
  left_join(glm) %>% 
  mutate(across(starts_with("scaled_"), as.vector))
rm(glm)
glimpse(hg)

#data for modeling - select for columns of use 
hg.model <- hg %>%
  select(WATERWAY,
         TYPE,
         DOW,
         nhdid,
         DATECOL2,
         YEARCOLL,
         SPEC,
         ANATHG,
         NOFISH,
         LGTHIN,
         scaled_length,
         HGPPM,
         Total_Wetland_Hectares,
         scaled_Total_Wetland_Hectares,
         Percent_Wetland,
         scaled_Percent_Wetland,
         logit_wetlands,
         scaled_logit_wetlands,
         WS_Lake_Ratio,
         log_WS_Lake_Ratio,
         scaled_WS_Lake_Ratio,
         centroid_lat,
         centroid_lon,
         max_depth,
         area,
         log_area,
         elevation,
         clarity,
         scaled_clarity)
```

#Exploring Predictors
```{r}
hg.model %>% 
  ggplot() +
  geom_histogram(aes(log(HGPPM)))

hg.model %>% 
  filter(SPEC == "WAE") %>% 
  ggplot() +
  geom_histogram(aes(scaled_length))

hg.model %>% 
  filter(SPEC == "NOP") %>% 
  ggplot() +
  geom_histogram(aes(scaled_length))

hg.model %>% 
  ggplot() +
  geom_histogram(aes(LGTHIN))

hg.model %>% 
  filter(SPEC == "WAE") %>% 
  ggplot() +
  geom_point(aes(LGTHIN, log(HGPPM))) +
  geom_smooth(aes(LGTHIN, log(HGPPM)))

hg.model %>% 
  filter(SPEC == "WAE") %>% 
  ggplot() +
  geom_point(aes(scaled_length, log(HGPPM))) +
  geom_smooth(aes(scaled_length, log(HGPPM)))

hg.model %>% 
  filter(SPEC == "WAE") %>% 
  ggplot() +
  geom_point(aes(logit_wetlands, log(HGPPM))) +
  geom_smooth(aes(logit_wetlands, log(HGPPM)))
```

#First attempt of modeling
```{r}
#ensure data clean for modeling
hg.model.filtered <- hg.model %>% 
  filter(TYPE == "Lake") %>% 
  filter(YEARCOLL >1996) %>% 
  filter(!(is.na(DOW) |
             is.na(ANATHG) |
             is.na(YEARCOLL) |
             is.na(LGTHIN) |
             is.na(Total_Wetland_Hectares)|
             is.na(Percent_Wetland) |
             is.na(WS_Lake_Ratio) |
             is.na(centroid_lat) |
             is.na(area) |
             is.na(clarity) |
             is.na(scaled_length))) %>% 
  mutate(year = factor(YEARCOLL),
         DOW = factor(DOW)) %>% 
  mutate(log.hg = log(HGPPM))
#summary of the data
summary(hg.model.filtered)
rm(hg.model, hg)

###################walleye model#################################
wae <- hg.model.filtered %>% 
  filter(SPEC == "WAE")

#simple linear mixed effects model to test before going Bayesian
fit.wae <- lmer(log.hg ~ scaled_length + 
                 logit_wetlands +
                 log_area +
                 log_WS_Lake_Ratio + 
                 clarity + 
                 (1|year) + 
                 (1|DOW),
              data = wae)
summary(fit.wae)


#brms model
fit.wae <- brm(log.hg ~ scaled_length +
               logit_wetlands + 
               log_area + 
               log_WS_Lake_Ratio +
               clarity + 
               (1|year) + 
               (1|DOW),
             data = wae,
             family = gaussian(),
             iter = 10000,
             warmup = 1000,
            chains = 3,
            cores = 10)
#save model run/read in saved model run
saveRDS(fit.wae, "WAE_model.rds")
fit.wae <- readRDS("WAE_model.rds")

#basic summary output
summary(fit.wae)
plot(fit.wae)
plot(conditional_effects(fit.wae))

#random effects for year
fit.wae %>%
  spread_draws(b_Intercept, r_year[year,]) %>% 
  median_qi(condition_mean = b_Intercept + r_year, .width = c(.95, .66)) %>%
  ggplot(aes(y = year, x = condition_mean,  xmin = .lower, xmax = .upper)) +
  geom_pointinterval()

fit.wae %>%
  spread_draws(b_Intercept, r_DOW[DOW,]) %>% 
  median_qi(condition_mean = b_Intercept + r_DOW, .width = c(.95, .66)) %>%
  ggplot(aes(y = as.factor(DOW), x = condition_mean,  xmin = .lower, xmax = .upper)) +
  geom_pointinterval()

chunks <- fit.wae %>%
  spread_draws(b_Intercept, r_DOW[DOW,]) %>% 
  median_qi(condition_mean = b_Intercept + r_DOW, .width = c(.95, .66)) %>%
  arrange(desc(condition_mean)) %>% 
  group_by(chunk = ceiling(row_number() / 50))

# Plot each chunk separately
plots <- list()
for (i in unique(chunks$chunk)) {
  plot_data <- chunks %>%
    filter(chunk == i) %>%
    ggplot(aes(y = as.factor(DOW), x = condition_mean, xmin = .lower, xmax = .upper)) +
    geom_pointinterval() +
    labs(title = paste("Chunk", i))
  
  plots[[i]] <- plot_data
}

# Print each plot
for (i in seq_along(plots)) {
  print(plots[[i]])
}

#predictive capacity 
pp_check(fit.wae, ndraws = 100)
loo.wae <- loo(fit.wae, save_psis = T)

print(loo.wae)
plot(loo.wae)
#marginal posterior predictive checks
yrep <- posterior_predict(fit.wae)
ppc_loo_pit_qq(
  y = wae$log.hg,
  yrep = yrep,
  lw = weights(loo.wae$psis_object)
)

#PIT overlay on unif
ppc_loo_pit_overlay(y = wae$log.hg, yrep = yrep, lw = weights(loo.wae$psis_object))

#50 random predictive poionts
keep_obs <- sample(1:10605, 50, replace = FALSE)
ppc_loo_intervals(y = wae$log.hg, 
                  yrep = yrep, 
                  psis_object = loo.wae$psis_object, 
                  subset = keep_obs,
                  order = "median")

rm(fit.wae, loo.wae, plot_data, plots, i, chunks, yrep, wae, keep_obs)
###############northern pike model#######################################
nop <- hg.model.filtered %>% 
  filter(SPEC == "NOP")

fit.nop <- lmer(log.hg ~ scaled_length + 
                 logit_wetlands +
                 log_area +
                 log_WS_Lake_Ratio + 
                 clarity + 
                 (1|year) + 
                 (1|DOW),
              data = nop)
summary(nop)

#brms model for nop
fit.nop <- brm(log.hg ~ scaled_length +
               logit_wetlands + 
               log_area + 
               log_WS_Lake_Ratio +
               clarity + 
               (1|year) + 
               (1|DOW),
             data = nop,
             family = gaussian(),
             iter = 10000,
             warmup = 1000,
            chains = 3,
            cores = 10)
saveRDS(fit.nop, "NOP_model.rds")

#basic summary output
summary(fit.nop)
plot(fit.nop)
plot(conditional_effects(fit.nop))

#random effects for year
fit.nop %>%
  spread_draws(b_Intercept, r_year[year,]) %>% 
  median_qi(condition_mean = b_Intercept + r_year, .width = c(.95, .66)) %>%
  ggplot(aes(y = year, x = condition_mean,  xmin = .lower, xmax = .upper)) +
  geom_pointinterval()

fit.nop %>%
  spread_draws(b_Intercept, r_DOW[DOW,]) %>% 
  median_qi(condition_mean = b_Intercept + r_DOW, .width = c(.95, .66)) %>%
  ggplot(aes(y = as.factor(DOW), x = condition_mean,  xmin = .lower, xmax = .upper)) +
  geom_pointinterval()

chunks <- fit.nop %>%
  spread_draws(b_Intercept, r_DOW[DOW,]) %>% 
  median_qi(condition_mean = b_Intercept + r_DOW, .width = c(.95, .66)) %>%
  arrange(desc(condition_mean)) %>% 
  group_by(chunk = ceiling(row_number() / 50))

# Plot each chunk separately
plots <- list()
for (i in unique(chunks$chunk)) {
  plot_data <- chunks %>%
    filter(chunk == i) %>%
    ggplot(aes(y = as.factor(DOW), x = condition_mean, xmin = .lower, xmax = .upper)) +
    geom_pointinterval() +
    labs(title = paste("Chunk", i))
  
  plots[[i]] <- plot_data
}

# Print each plot
for (i in seq_along(plots)) {
  print(plots[[i]])
}

#predictive capacity 
pp_check(fit.nop, ndraws = 100)
loo.nop <- loo(fit.nop, save_psis = T)

print(loo.nop)
plot(loo.nop)
#marginal posterior predictive checks
yrep <- posterior_predict(fit.nop)
ppc_loo_pit_qq(
  y = nop$log.hg,
  yrep = yrep,
  lw = weights(loo.nop$psis_object)
)
#PIT overlay on unif
ppc_loo_pit_overlay(y = nop$log.hg, yrep = yrep, lw = weights(loo.nop$psis_object))

#50 random predictive poionts
keep_obs <- sample(1:15054, 50, replace = FALSE)
ppc_loo_intervals(y = nop$log.hg, 
                  yrep = yrep, 
                  psis_object = loo.nop$psis_object, 
                  subset = keep_obs,
                  order = "median")
rm(chunks, fit.nop, loo.nop, nop, plot_data, plots, yrep, i, keep_obs)
###############Bluegill##############
blg <- hg.model.filtered %>% 
  filter(SPEC == "BLG")

#brms model for nop
fit.blg <- brm(log.hg ~ scaled_length +
               logit_wetlands + 
               log_area + 
               log_WS_Lake_Ratio +
               clarity + 
               (1|year) + 
               (1|DOW),
             data = blg,
             family = gaussian(),
             iter = 10000,
             warmup = 1000,
            chains = 3,
            cores = 10)
saveRDS(fit.blg, "BLG_model.rds")

#basic summary output
summary(fit.blg)
plot(fit.blg)
plot(conditional_effects(fit.blg))

#random effects for year
fit.blg %>%
  spread_draws(b_Intercept, r_year[year,]) %>% 
  median_qi(condition_mean = b_Intercept + r_year, .width = c(.95, .66)) %>%
  ggplot(aes(y = year, x = condition_mean,  xmin = .lower, xmax = .upper)) +
  geom_pointinterval()

chunks <- fit.blg %>%
  spread_draws(b_Intercept, r_DOW[DOW,]) %>% 
  median_qi(condition_mean = b_Intercept + r_DOW, .width = c(.95, .66)) %>%
  arrange(desc(condition_mean)) %>% 
  group_by(chunk = ceiling(row_number() / 50))

# Plot each chunk separately
plots <- list()
for (i in unique(chunks$chunk)) {
  plot_data <- chunks %>%
    filter(chunk == i) %>%
    ggplot(aes(y = as.factor(DOW), x = condition_mean, xmin = .lower, xmax = .upper)) +
    geom_pointinterval() +
    labs(title = paste("Chunk", i))
  
  plots[[i]] <- plot_data
}

# Print each plot
for (i in seq_along(plots)) {
  print(plots[[i]])
}

#predictive capacity 
pp_check(fit.blg, ndraws = 100)
loo.blg <- loo(fit.blg, save_psis = T)

print(loo.blg)
plot(loo.blg)
#marginal posterior predictive checks
yrep <- posterior_predict(fit.blg)
ppc_loo_pit_qq(
  y = blg$log.hg,
  yrep = yrep,
  lw = weights(loo.blg$psis_object)
)
#PIT overlay on unif
ppc_loo_pit_overlay(y = blg$log.hg, yrep = yrep, lw = weights(loo.blg$psis_object))

#50 random predictive poionts
keep_obs <- sample(1:1660, 50, replace = FALSE)
ppc_loo_intervals(y = blg$log.hg, 
                  yrep = yrep, 
                  psis_object = loo.blg$psis_object, 
                  subset = keep_obs,
                  order = "median")
rm(chunks, fit.blg, loo.blg, blg, plot_data, plots, yrep, i, keep_obs)

################largemouth bass####################################
lmb <- hg.model.filtered %>% 
  filter(SPEC == "LMB")

#brms model for nop
fit.lmb <- brm(log.hg ~ scaled_length +
               logit_wetlands + 
               log_area + 
               log_WS_Lake_Ratio +
               clarity + 
               (1|year) + 
               (1|DOW),
             data = lmb,
             family = gaussian(),
             iter = 10000,
             warmup = 1000,
            chains = 3,
            cores = 10)
saveRDS(fit.lmb, "LMB_model.rds")

#basic summary output
summary(fit.lmb)
plot(fit.lmb)
plot(conditional_effects(fit.lmb))

#random effects for year
fit.lmb %>%
  spread_draws(b_Intercept, r_year[year,]) %>% 
  median_qi(condition_mean = b_Intercept + r_year, .width = c(.95, .66)) %>%
  ggplot(aes(y = year, x = condition_mean,  xmin = .lower, xmax = .upper)) +
  geom_pointinterval()

chunks <- fit.lmb %>%
  spread_draws(b_Intercept, r_DOW[DOW,]) %>% 
  median_qi(condition_mean = b_Intercept + r_DOW, .width = c(.95, .66)) %>%
  arrange(desc(condition_mean)) %>% 
  group_by(chunk = ceiling(row_number() / 50))

# Plot each chunk separately
plots <- list()
for (i in unique(chunks$chunk)) {
  plot_data <- chunks %>%
    filter(chunk == i) %>%
    ggplot(aes(y = as.factor(DOW), x = condition_mean, xmin = .lower, xmax = .upper)) +
    geom_pointinterval() +
    labs(title = paste("Chunk", i))
  
  plots[[i]] <- plot_data
}

# Print each plot
for (i in seq_along(plots)) {
  print(plots[[i]])
}

#predictive capacity 
pp_check(fit.lmb, ndraws = 100)
loo.lmb <- loo(fit.lmb, save_psis = T)

print(loo.lmb)
plot(loo.lmb)
#marginal posterior predictive checks
yrep <- posterior_predict(fit.lmb)
ppc_loo_pit_qq(
  y = lmb$log.hg,
  yrep = yrep,
  lw = weights(loo.lmb$psis_object)
)
#PIT overlay on unif
ppc_loo_pit_overlay(y = lmb$log.hg, yrep = yrep, lw = weights(loo.lmb$psis_object))

#50 random predictive poionts
keep_obs <- sample(1:1470, 50, replace = FALSE)
ppc_loo_intervals(y = lmb$log.hg, 
                  yrep = yrep, 
                  psis_object = loo.lmb$psis_object, 
                  subset = keep_obs,
                  order = "median")
rm(chunks, fit.lmb, loo.lmb, lmb, plot_data, plots, yrep, i, keep_obs)

####################yellow perch###########################
yep <- hg.model.filtered %>% 
  filter(SPEC == "YEP")

#brms model for nop
fit.yep <- brm(log.hg ~ scaled_length +
               logit_wetlands + 
               log_area + 
               log_WS_Lake_Ratio +
               clarity + 
               (1|year) + 
               (1|DOW),
             data = yep,
             family = gaussian(),
             iter = 10000,
             warmup = 1000,
            chains = 3,
            cores = 10)
saveRDS(fit.yep, "YEP_model.rds")

#basic summary output
summary(fit.yep)
plot(fit.yep)
plot(conditional_effects(fit.yep))

#random effects for year
fit.yep %>%
  spread_draws(b_Intercept, r_year[year,]) %>% 
  median_qi(condition_mean = b_Intercept + r_year, .width = c(.95, .66)) %>%
  ggplot(aes(y = year, x = condition_mean,  xmin = .lower, xmax = .upper)) +
  geom_pointinterval()

chunks <- fit.yep %>%
  spread_draws(b_Intercept, r_DOW[DOW,]) %>% 
  median_qi(condition_mean = b_Intercept + r_DOW, .width = c(.95, .66)) %>%
  arrange(desc(condition_mean)) %>% 
  group_by(chunk = ceiling(row_number() / 50))

# Plot each chunk separately
plots <- list()
for (i in unique(chunks$chunk)) {
  plot_data <- chunks %>%
    filter(chunk == i) %>%
    ggplot(aes(y = as.factor(DOW), x = condition_mean, xmin = .lower, xmax = .upper)) +
    geom_pointinterval() +
    labs(title = paste("Chunk", i))
  
  plots[[i]] <- plot_data
}

# Print each plot
for (i in seq_along(plots)) {
  print(plots[[i]])
}

#predictive capacity 
pp_check(fit.yep, ndraws = 100)
loo.yep <- loo(fit.yep, save_psis = T)

print(loo.yep)
plot(loo.yep)
#marginal posterior predictive checks
yrep <- posterior_predict(fit.yep)
ppc_loo_pit_qq(
  y = yep$log.hg,
  yrep = yrep,
  lw = weights(loo.yep$psis_object)
)
#PIT overlay on unif
ppc_loo_pit_overlay(y = yep$log.hg, yrep = yrep, lw = weights(loo.yep$psis_object))

#50 random predictive poionts
keep_obs <- sample(1:1389, 50, replace = FALSE)
ppc_loo_intervals(y = yep$log.hg, 
                  yrep = yrep, 
                  psis_object = loo.yep$psis_object, 
                  subset = keep_obs,
                  order = "median")
rm(chunks, fit.yep, loo.yep, yep, plot_data, plots, yrep, i, keep_obs)
```

#HMSC
```{r}
library(Hmsc)

#filtered data
hg.model.filtered <- hg.model %>% 
  filter(TYPE == "Lake") %>% 
  filter(YEARCOLL >1996) %>% 
  filter(!(is.na(DOW) |
             is.na(ANATHG) |
             is.na(YEARCOLL) |
             is.na(LGTHIN) |
             is.na(Total_Wetland_Hectares)|
             is.na(Percent_Wetland) |
             is.na(WS_Lake_Ratio) |
             is.na(centroid_lat) |
             is.na(area) |
             is.na(clarity) |
             is.na(scaled_length))) %>% 
  mutate(year = factor(YEARCOLL),
         DOW = factor(DOW)) %>% 
  mutate(log.hg = log(HGPPM))
#summary of the data
summary(hg.model.filtered)
rm(hg.model, hg)


#three species
three_spec <- hg.model.filtered %>% 
  filter(SPEC %in% c("WAE", "NOP", "BLC")) %>% 
  select(DOW,
         year,
         SPEC,
         log.hg,
         scaled_length,
         scaled_Percent_Wetland,
         log_WS_Lake_Ratio,
         log_area,
         scaled_clarity) 

test <- three_spec %>% 
  select(SPEC,
         log.hg,
         DOW,
         year) %>% 
  pivot_wider(id_cols = c(DOW, year),
    names_from = SPEC,
              values_from = log.hg)
  
  n = 100
x1 = rnorm(n)
x2 = rnorm(n)
XData = data.frame(x1=x1,x2=x2)
alpha = c(0,0,0,0,0)
beta1 = c(1,1,-1,-1,0)
beta2 = c(1,-1,1,-1,0)
sigma = c(1,1,1,1,1)
L = matrix(NA,nrow=n,ncol=5)
1
Y = matrix(NA,nrow=n,ncol=5)
for (j in 1:5){
L[,j] = alpha[j] + beta1[j]*x1 + beta2[j]*x2
Y[,j] = L[,j] + rnorm(n, sd = sigma[j])
}

#trying with brms
all_species <- hg.model.filtered %>% 
  filter(SPEC %in% c("NOP", "BLC", "WAE", "BLG", "LMB"))

fit.lmb <- brm(log.hg ~ scaled_length +
               logit_wetlands + 
               log_area + 
               log_WS_Lake_Ratio +
               clarity + 
               (1|year) + 
               (1|DOW/SPEC),
             data = all_species,
             family = gaussian(),
             iter = 10000,
             warmup = 1000,
            chains = 3,
            cores = 10)
```


#Old code
```{r}
################linking to lagos data############
#load all lagos data
lagos <- lagosne_load()
#extract data relavent to Hg
#epi_nutr contains limno parameters of interest - espically carbon
#hu12 conn gives watershed level paramters for wetlends
#huc12 lulc gives parameters for watershed level landcover
#state gives state level parameters
#filter for just MN lakes 
lg <- left_join(lagos$epi_nutr, lagos$locus)
lg <- left_join(lg, lagos$hu12.conn)
lg <- left_join(lg, lagos$hu12.lulc)
lg <- left_join(lg, lagos$state)
lg.sum <- lg %>% 
  filter(state == "MN") %>% 
  select(state,
         state_name,
         sampledate,
         nhdid,
         hu12_zoneid,
         gnis_name,
         nhd_lat,
         nhd_long,
         lake_area_ha,
         lake_perim_meters,
         doc,
         doc_qual,
         doc_censorcode,
         doc_detectionlimit,
         doc_labmethodname,
         toc,
         toc_qual,
         toc_censorcode,
         toc_detectionlimit,
         toc_labmethodname,
         secchi,
         secchi_qual,
         secchi_censorcode,
         secchi_methodinfo,
         hu12_nlcd2011_pct_90,
         hu12_nlcd2011_ha_90,
         hu12_nlcd2011_pct_95,
         hu12_nlcd2011_ha_95) %>% 
  group_by(nhdid) %>% 
  summarise(meanDOC = mean(doc, na.rm = T),
            meanTOC = mean(toc, na.rm = T),
            meanSECCHI = mean(secchi, na.rm = T),
            mean95 = mean(hu12_nlcd2011_pct_95, na.rm = T),
            mean90 = mean(hu12_nlcd2011_pct_90, na.rm = T),
            meanAREA = mean(lake_area_ha, na.rm = T))

#joining to Hg data
hg.lg <- left_join(hg, lg.sum)
```

